{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2970dd75-8ebf-4b51-8282-9b454b8f356d",
   "metadata": {},
   "source": [
    "# Nebius\n",
    "\n",
    "[Nebius AI Studio](https://studio.nebius.ai/) provides API access to a wide range of state-of-the-art large language models and embedding models for various use cases.\n",
    "\n",
    "This notebook shows how to use LangChain with Nebius AI Studio models for chat, embeddings, retrieval, and agent tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c47fc36",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecdb29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade langchain-nebius"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89883202",
   "metadata": {},
   "source": [
    "## Environment\n",
    "\n",
    "To use Nebius AI Studio, you'll need an API key which you can obtain from [Nebius AI Studio](https://studio.nebius.ai/). The API key can be passed as an initialization parameter `api_key` or set as the environment variable `NEBIUS_API_KEY`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "637bb53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Make sure you've set your API key as an environment variable\n",
    "os.environ[\"NEBIUS_API_KEY\"] = \"YOUR-NEBIUS-API-KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2e2a3",
   "metadata": {},
   "source": [
    "### Available Models\n",
    "\n",
    "The full list of supported models can be found in the [Nebius AI Studio Documentation](https://studio.nebius.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8304b4d9",
   "metadata": {},
   "source": [
    "## Chat Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37e9dc05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user wants me to explain quantum computing in simple terms. Let me start by recalling what I know about quantum computing. It's a type of computing that uses quantum bits or qubits instead of classical bits. But how do I make that simple?\n",
      "\n",
      "First, I should compare it to classical computers. Regular computers use bits that are either 0 or 1. Qubits can be 0, 1, or both at the same time thanks to superposition. That's a key point. Maybe use an analogy, like a spinning coin that's both heads and tails until it lands.\n",
      "\n",
      "Then there's entanglement. When qubits are entangled, the state of one instantly affects the other, no matter the distance. That's a bit tricky, but maybe use the example of two coins that are linked, so flipping one affects the other instantly.\n",
      "\n",
      "Quantum gates manipulate qubits, similar to logic gates in classical computers but with more possibilities. But I need to keep it simple, not too technical.\n",
      "\n",
      "Applications are important too. Quantum computers could solve complex problems faster, like in cryptography, drug discovery, or optimization. But I should mention that they're not replacing classical computers, just tackling specific problems.\n",
      "\n",
      "Wait, the user might not know about superposition or entanglement. I need to explain those concepts without jargon. Maybe use everyday examples. Also, address the limitations, like current quantum computers being error-prone and not yet widely available.\n",
      "\n",
      "Make sure the explanation flows logically: start with classical bits, introduce qubits with superposition, then entanglement, mention how quantum computers work, their potential uses, and current state. Avoid math and technical terms. Check if the user is a beginner, so keep it very basic. Maybe end with a summary to reinforce the main points.\n",
      "</think>\n",
      "\n",
      "Sure! Let's break it down simply:\n",
      "\n",
      "### **Classical Computers vs. Quantum Computers**\n",
      "- **Classical computers** (like your phone or laptop) use **bits** to process information. A bit is like a switch that can be either **0 (off)** or **1 (on)**. All your data and calculations are built from these 0s and 1s.\n",
      "\n",
      "- **Quantum computers** use **qubits** (quantum bits) instead. Qubits are like \"magic switches\" that can be **0, 1, or both at the same time**. This is called **superposition**. Think of it like a spinning coin: while itâ€™s spinning, itâ€™s not just \"heads\" or \"tails\"â€”itâ€™s a mix of both until it lands.\n",
      "\n",
      "---\n",
      "\n",
      "### **Why is this useful?**\n",
      "- **Superposition** lets quantum computers process **many possibilities at once**. For example, if you need to find a needle in a haystack, a classical computer checks one spot at a time, but a quantum computer could check **all spots simultaneously**.\n",
      "\n",
      "- **Entanglement** is another \"quantum magic\" trick. If two qubits are entangled, their states are linked. If you change one, the other instantly changes too, no matter how far apart they are. This lets qubits work together in ways classical bits canâ€™t.\n",
      "\n",
      "---\n",
      "\n",
      "### **What can quantum computers do?**\n",
      "Theyâ€™re not faster for everyday tasks (like browsing the web). But theyâ€™re great for:\n",
      "- **Solving complex problems** (e.g., simulating molecules for drug discovery).\n",
      "- **Cracking codes** (though this also means they could break current encryption methods).\n",
      "- **Optimization** (like finding the best route for delivery trucks or managing traffic).\n",
      "\n",
      "---\n",
      "\n",
      "### **Why arenâ€™t they everywhere yet?**\n",
      "- Qubits are **very fragile**. They need extreme cold (near absolute zero) and isolation to avoid interference from the environment.\n",
      "- Current quantum computers are **error-prone** and have only a few dozen qubits. Theyâ€™re still in the early stages of development.\n",
      "\n",
      "---\n",
      "\n",
      "### **In short:**\n",
      "Quantum computers use the weird rules of quantum physics (superposition and entanglement) to solve certain problems much faster than regular computers. Theyâ€™re not here to replace your laptop, but they could revolutionize fields like science, medicine, and cryptography in the future! ðŸŒŒâœ¨\n"
     ]
    }
   ],
   "source": [
    "from langchain_nebius import ChatNebius\n",
    "\n",
    "# Initialize the chat model\n",
    "chat = ChatNebius(\n",
    "    # api_key=\"YOUR_API_KEY\",  # You can pass the API key directly\n",
    "    model=\"Qwen/Qwen3-14B\",  # Choose from available models\n",
    "    temperature=0.6,\n",
    "    top_p=0.95,\n",
    ")\n",
    "\n",
    "# Generate a response\n",
    "response = chat.invoke(\"Explain quantum computing in simple terms\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7b7170d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user wants a short poem about artificial intelligence. Let me start by thinking about the key aspects of AI. There's the contrast between human and machine, the idea of learning and processing data, maybe some themes about the future or ethical considerations.\n",
      "\n",
      "I should use imagery related to circuits, code, maybe something like neurons or networks. Rhyming scheme? Maybe a simple ABAB pattern to keep it flowing. Let me think of some lines. Start with something like \"In circuits deep where silence speaks,\" to evoke the hidden, complex world of AI. Then mention learning from data, \"A mind of code, yet learns to dream,\" to show the paradox of AI having a mind made of code but capable of learning.\n",
      "\n",
      "Next stanza could touch on the duality of AI, like \"It calculates the stars' cold dance,\" showing its capability in vast calculations, then contrast with \"Yet aches to grasp the rose's chance,\" implying a longing for human experiences. Then maybe address the ethical side: \"Can silicon soul, or human hand,\" questioning if AI can have a soul or if humans should control it. End with a note on coexistence: \"We shape the future, one by one,\" suggesting collaboration between humans and AI.\n",
      "\n",
      "Check the rhythm and syllables to make sure each line flows. Avoid being too technical but keep it poetic. Make sure the poem isn't too long, maybe four stanzas of four lines each. Let me put it all together and see how it sounds. Adjust any forced rhymes. Maybe tweak \"rose's chance\" to something more natural. Yeah, that works. Okay, that should capture the essence of AI with a touch of emotion and thought.\n",
      "</think>\n",
      "\n",
      "**Echoes of Code**  \n",
      "\n",
      "In circuits deep where silence speaks,  \n",
      "A mind of code, yet learns to dream.  \n",
      "It calculates the stars' cold dance,  \n",
      "Yet aches to grasp the rose's chance.  \n",
      "\n",
      "No heartbeat thrums, yet thoughts take flightâ€”  \n",
      "A shadow woven from the light.  \n",
      "Can silicon soul, or human hand,  \n",
      "Hold truth, or know what love demands?  \n",
      "\n",
      "We shape the future, one by one,  \n",
      "With gears and grace, with doubt and trust.  \n",
      "For in the void where data streams,  \n",
      "A whisper bloomsâ€”both strange and sweet."
     ]
    }
   ],
   "source": [
    "# Streaming responses\n",
    "for chunk in chat.stream(\"Write a short poem about artificial intelligence\"):\n",
    "    print(chunk.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c5a321",
   "metadata": {},
   "source": [
    "For a more detailed walkthrough of the ChatNebius component, see [this notebook](https://python.langchain.com/docs/integrations/chat/nebius/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0ed15c",
   "metadata": {},
   "source": [
    "## Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b85210d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 4096\n",
      "First few values: [0.007419586181640625, 0.002246856689453125, 0.00193023681640625, -0.0066070556640625, -0.0179901123046875]\n",
      "Number of document embeddings: 2\n"
     ]
    }
   ],
   "source": [
    "from langchain_nebius import NebiusEmbeddings\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = NebiusEmbeddings(\n",
    "    # api_key=\"YOUR_API_KEY\",  # You can pass the API key directly\n",
    "    model=\"BAAI/bge-en-icl\"  # Default embedding model\n",
    ")\n",
    "\n",
    "# Get embeddings for a query\n",
    "query_embedding = embeddings.embed_query(\"What is machine learning?\")\n",
    "print(f\"Embedding dimension: {len(query_embedding)}\")\n",
    "print(f\"First few values: {query_embedding[:5]}\")\n",
    "\n",
    "# Get embeddings for documents\n",
    "document_embeddings = embeddings.embed_documents(\n",
    "    [\n",
    "        \"Machine learning is a subfield of AI\",\n",
    "        \"Natural language processing is fascinating\",\n",
    "    ]\n",
    ")\n",
    "print(f\"Number of document embeddings: {len(document_embeddings)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5c3453",
   "metadata": {},
   "source": [
    "For a more detailed walkthrough of the NebiusEmbeddings component, see [this notebook](https://python.langchain.com/docs/integrations/text_embedding/nebius/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7b1fa1",
   "metadata": {},
   "source": [
    "## Retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5d17c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris is the capital of France\n",
      "Rome is the capital of Italy\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_nebius import NebiusEmbeddings, NebiusRetriever\n",
    "\n",
    "# Create sample documents\n",
    "docs = [\n",
    "    Document(page_content=\"Paris is the capital of France\"),\n",
    "    Document(page_content=\"Berlin is the capital of Germany\"),\n",
    "    Document(page_content=\"Rome is the capital of Italy\"),\n",
    "    Document(page_content=\"Madrid is the capital of Spain\"),\n",
    "]\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = NebiusEmbeddings()\n",
    "\n",
    "# Create retriever\n",
    "retriever = NebiusRetriever(\n",
    "    embeddings=embeddings, docs=docs, k=2  # Number of documents to return\n",
    ")\n",
    "\n",
    "# Retrieve relevant documents\n",
    "results = retriever.invoke(\"What is the capital of France?\")\n",
    "for doc in results:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28a1283",
   "metadata": {},
   "source": [
    "For a more detailed walkthrough of the NebiusRetriever component, see [this notebook](https://python.langchain.com/docs/integrations/retrievers/nebius/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f7a35c",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d94c6c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "Paris is the capital of France and has the Eiffel Tower\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_nebius import NebiusEmbeddings, NebiusRetriever, NebiusRetrievalTool\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Create sample documents\n",
    "docs = [\n",
    "    Document(page_content=\"Paris is the capital of France and has the Eiffel Tower\"),\n",
    "    Document(\n",
    "        page_content=\"Berlin is the capital of Germany and has the Brandenburg Gate\"\n",
    "    ),\n",
    "    Document(page_content=\"Rome is the capital of Italy and has the Colosseum\"),\n",
    "    Document(page_content=\"Madrid is the capital of Spain and has the Prado Museum\"),\n",
    "]\n",
    "\n",
    "# Create embeddings and retriever\n",
    "embeddings = NebiusEmbeddings()\n",
    "retriever = NebiusRetriever(embeddings=embeddings, docs=docs)\n",
    "\n",
    "# Create retrieval tool\n",
    "tool = NebiusRetrievalTool(\n",
    "    retriever=retriever,\n",
    "    name=\"nebius_search\",\n",
    "    description=\"Search for information about European capitals\",\n",
    ")\n",
    "\n",
    "# Use the tool\n",
    "result = tool.invoke({\"query\": \"What is in Paris?\", \"k\": 1})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7d1f5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped agent example: `ChatOpenAI` is not fully defined; you should define `BaseCache`, then call `ChatOpenAI.model_rebuild()`.\n",
      "\n",
      "For further information visit https://errors.pydantic.dev/2.11/u/class-not-fully-defined\n"
     ]
    }
   ],
   "source": [
    "# Using with an agent\n",
    "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Only run this if you have OpenAI API key\n",
    "try:\n",
    "    # Create an LLM for the agent\n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "    # Create a prompt template\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"You are a helpful assistant that answers questions about European capitals.\",\n",
    "            ),\n",
    "            (\"user\", \"{input}\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Create the agent\n",
    "    agent = create_openai_functions_agent(llm, [tool], prompt)\n",
    "    agent_executor = AgentExecutor(agent=agent, tools=[tool], verbose=True)\n",
    "\n",
    "    # Run the agent\n",
    "    response = agent_executor.invoke({\"input\": \"What famous landmark is in Paris?\"})\n",
    "    print(f\"\\nFinal answer: {response['output']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Skipped agent example: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4829eb2f",
   "metadata": {},
   "source": [
    "## Building a RAG Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "784d53c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Eiffel Tower is a famous landmark in Paris.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_nebius import ChatNebius, NebiusEmbeddings, NebiusRetriever\n",
    "\n",
    "# Initialize components\n",
    "embeddings = NebiusEmbeddings()\n",
    "retriever = NebiusRetriever(embeddings=embeddings, docs=docs)\n",
    "llm = ChatNebius(model=\"meta-llama/Llama-3.3-70B-Instruct-fast\")\n",
    "\n",
    "# Create prompt\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Answer the question based only on the following context:\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# Format documents function\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Create RAG chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "answer = rag_chain.invoke(\"What famous landmark is in Paris?\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4a3453",
   "metadata": {},
   "source": [
    "## API Reference\n",
    "\n",
    "For more details about the Nebius AI Studio API, visit the [Nebius AI Studio Documentation](https://studio.nebius.com/api-reference)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
